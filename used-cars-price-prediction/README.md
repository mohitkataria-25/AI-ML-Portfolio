# Used Cars Price Prediction â€” End-to-End ML Pipeline

An end-to-end machine learning system that predicts used car prices using classical tree-based models (primary) and an optional neural network baseline.  
This project demonstrates **modular ML architecture**, **clean engineering practices**, **hyperparameter tuning**, and a **production-like inference pipeline**.

---

## ğŸš€ Project Highlights

### âœ”ï¸ Modular ML Codebase  
Separated into `preprocessing`, `models`, `training`, `evaluation`, `tuning`, and `inference`.

### âœ”ï¸ Multi-Model Comparison  
- Random Forest (primary model)  
- XGBoost (primary model)  
- Neural Network (Keras Sequential, experimental baseline)

### âœ”ï¸ Hyperparameter Tuning  
Built using `RandomizedSearchCV` for Random Forest and XGBoost.

### âœ”ï¸ Model Persistence  
- Sklearn & XGBoost â†’ Joblib (`.pkl`)  
- Neural Network â†’ Keras Save (`.h5`)

### âœ”ï¸ Inference Pipeline  
Evaluate saved models or run predictions on new samples.

---

## ğŸ“‚ Repository Structure

```
used-cars-price-prediction/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ inference.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ tuning.py
â”‚
â”œâ”€â”€ metrics/          
â”œâ”€â”€ models/           
â”œâ”€â”€ notebooks/        
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Installation

```bash
pip install -r requirements.txt
```

---

## ğŸ§  How It Works

### 1ï¸âƒ£ Preprocessing
- Numeric extraction  
- One-hot encoding  
- Train/validation/test split  
- Standardization  

### 2ï¸âƒ£ Model Training
```bash
python -m src.train
```

With tuning:
```bash
python -m src.train --tune
```

### 3ï¸âƒ£ Model Selection Rationale
- The dataset is **tabular, structured data** with mixed numeric and categorical features.
- In this setting, **tree-based ensembles** (Random Forest, XGBoost) typically offer the best balance of performance, robustness, and training speed.
- A small feedforward **neural network** is included as an experimental baseline, but in practice the tree-based models performed as well or better while being faster and simpler to train on CPU-only environments.
- For any deployment or production-style use, this project treats **Random Forest and XGBoost as the primary candidate models**, with the neural network used mainly for comparison and learning purposes.

---

## ğŸ” Inference

```bash
python -m src.inference --model_path     models/random_forest/used_cars_rf.pkl     models/xgboost/used_cars_xgb.pkl     models/neural_net/used_cars_mlp.h5
```

---

## ğŸ“Š Example Comparison Table

| Model | RMSE | MAE | RÂ² |
|-------|------|-----|----|
| Random Forest | â€¦ | â€¦ | â€¦ |
| XGBoost | â€¦ | â€¦ | â€¦ |
| Neural Network | â€¦ | â€¦ | â€¦ |

Actual results (with Random Forest and XGBoost usually outperforming the neural network on this tabular dataset) are saved to `/metrics/`.

---

## ğŸ› ï¸ Technologies

Python, Pandas, NumPy, Scikit-Learn, XGBoost, TensorFlow/Keras, Joblib, Matplotlib.

---

## ğŸ‘¤ Author

**Mohit Kataria**  
Senior Software Engineer â€¢ Data & ML Engineering

---

## â­ Star the repo if you found it helpful!
